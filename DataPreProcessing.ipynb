{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59370ad1-489b-4068-801c-a5848985b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries:\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf485352-633a-4452-9e1c-0c208f7b3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/umassdgithub/Fall-2023-DataViz/main/Week-8-ForceSimulator/data/data_scopus.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee49e1e-717e-4b1c-a906-79a4bb262a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns which do not have values for the below\n",
    "df = df.dropna(subset=['Author(s) ID','Year','Authors','Authors with affiliations'])\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating nodes\n",
    "G = nx.Graph()\n",
    "nodes = {}\n",
    "for _, row in df.iterrows():\n",
    "    # Extract authors from the \"Authors\" column\n",
    "    authors = row['Authors'].split(',')\n",
    "    author_Id = row['Author(s) ID'].split(';')\n",
    "    Title=row['Title']\n",
    "    Year=row['Year']\n",
    "    Citations=row['Cited by']\n",
    "    Publisher=row['Publisher']\n",
    "    auth_w_aff=row['Authors with affiliations']\n",
    "\n",
    "    # Adding authors as nodes\n",
    "\n",
    "    for author in range(len(authors)):\n",
    "\n",
    "        aid= author_Id[author]\n",
    "        auth_name= ';'.join(authors)\n",
    "        title=Title\n",
    "\n",
    "        if(aid!=\"\"):\n",
    "         nodes={'id':aid,\n",
    "          \"Authors\": auth_name,\n",
    "          \"Title\": title,\n",
    "          \"Year\": Year,\n",
    "          \"Citations\": Citations,\n",
    "          \"Publisher\": Publisher,\n",
    "          \"Author with affiliations\":auth_w_aff\n",
    "           }\n",
    "         G.add_node(aid,**nodes)\n",
    "from networkx.readwrite import json_graph\n",
    "with open(\"publication_network.json\", \"w\") as f:\n",
    "    json.dump(json_graph.node_link_data(G), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges\n",
    "# Load the data from the JSON file\n",
    "with open('publication_network.json', 'r') as infile:\n",
    "    data = json.load(infile)\n",
    "newnodes=[]\n",
    "G=nx.Graph()\n",
    "def get_author_country(authors_with_affiliations):\n",
    "    first_affiliation = authors_with_affiliations.split(';')[0].strip()\n",
    "    country = first_affiliation.split(',')[-1].strip()\n",
    "    return country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_data in data['nodes']:\n",
    "    eid = node_data.get('id')\n",
    "    authors=node_data.get('Authors')\n",
    "    title = node_data.get('Title')\n",
    "    year = node_data.get('Year')\n",
    "    citations = node_data.get('Citations')\n",
    "    publisher = node_data.get('Publisher')\n",
    "\n",
    "    authors_with_affiliations = str(node_data.get('Author with affiliations'))\n",
    "\n",
    "    country = get_author_country(authors_with_affiliations)\n",
    "\n",
    "    G.add_node(eid,authors=authors, title=title, year=year, citations=citations, publisher=publisher,authors_with_affiliations=authors_with_affiliations, country=country)\n",
    "\n",
    "\n",
    "clusters = list(nx.connected_components(G))\n",
    "\n",
    "#Assigning class\n",
    "class_mapping = {node: idx for idx, cluster in enumerate(clusters) for node in cluster}\n",
    "nx.set_node_attributes(G, class_mapping, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthorship_dict = {}\n",
    "for row in df.iterrows():\n",
    "    authors = row[1]['Author(s) ID'].split(';')\n",
    "    for i in range(len(authors)):\n",
    "      for j in range(i+1, len(authors)):\n",
    "        if(authors[i]!=\"\" and authors[j]!=\"\"):\n",
    "          G.add_edge(authors[i], authors[j])\n",
    "\n",
    "coauthorship_data = {'nodes': [{'id': node, **G.nodes[node]} for node in G.nodes()],'links': [{'source': source, 'target': target} for source, target in G.edges()]}\n",
    "\n",
    "with open('authorsdata.json', 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(coauthorship_data, outfile, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
